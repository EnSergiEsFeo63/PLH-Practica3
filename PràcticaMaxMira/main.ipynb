{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracció d'entitats anomenades"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectiu d'aquesta pràctica era fer un reconeixedor d'entitats anomenades amb conditional random fields. També experimentar amb diferents \"features_funcionts\" i amb diferents tipus de codificacions. Nosaltres vam estructurar l'experimentació de la següent forma:\n",
    "\n",
    "- Primer vam provar diferents tipus de funcions per decidir quines utilitzar\n",
    "\n",
    "- En segon lloc, vam provar diferents contexts en els quals aplicar aquestes funcions\n",
    "\n",
    "- Després vam posar a prova ambdós models a les diferents codificacions per escollir-ne una per cada idioma.\n",
    "\n",
    "-Un cop els models van estar fets, vam provar-los a la partició de test\n",
    "\n",
    "A continuació el codi i explicació de cada bloc de la nostra pràctica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Experimentació de \"feature functions\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import de les dades i preprocessament"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En primer lloc, vam importar les dades d'entrenament, validació i test de cada un dels dos idiomes. Aquestes dades venien en la codificació \"BIO\". Més endavant aquests tags es tractarien per provar altres codificacions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     C:\\Users\\maxmg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "import nltk\n",
    "nltk.download('conll2002')\n",
    "from nltk.corpus import conll2002\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train = conll2002.iob_sents('esp.train') # Train\n",
    "esp_testa = conll2002.iob_sents('esp.testa') # Development\n",
    "esp_testb = conll2002.iob_sents('esp.testb') # Test\n",
    "\n",
    "ned_train = conll2002.iob_sents('ned.train') # Train\n",
    "ned_testa = conll2002.iob_sents('ned.testa') # Development\n",
    "ned_testb = conll2002.iob_sents('ned.testb') # Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocessing el vam idear molt centrats en els passos següents. Sabíem que voldríem experimentar amb diferents combinacions \"feature functions\", i aplicades a diferents contextos dels tokens, i per tant imaginàvem que acabaríem creant un alt nombre de models.\n",
    "\n",
    "Per tal d'agilitzar-ho i de fer-ho de la manera més eficient possible, vam decidir calcular les \"feature functions\" de cada token al \"preprocessing\". Aquest plantejament implicava dos principals avantatges:\n",
    "\n",
    "- La primera és que en el cas de voler agafar informació del context d'un token, cosa que sabíem que acabaríem fent, no caldria recalcular vàries vegades les funcions d'un token, només caldria accedir a un índex diferent i d'allà prendre les \"feature functions\" convenients. \n",
    "\n",
    "- La segona es que en cas de fer \"grid search\" també ens estalviaríem molt de temps de computació, ja que no caldria que es calculessin les \"feature functions\" a cada model, només es calculen un cop, i els diferents models el que fan és agafar-les o no agafar-les.\n",
    "\n",
    "Així que el primer pas que vam haver de fer és definir quines funcions es calculen per cada token. Les 5 funcions bàsiques les vam mantenir i en vam afegir 5 funcions noves:\n",
    "\n",
    "1. Prefixos fins a longitud 3\n",
    "\n",
    "2. El Pos-Tag del token\n",
    "\n",
    "3. La longitud del token\n",
    "\n",
    "4. Si el token és una stop-word\n",
    "\n",
    "Utilitzant llistes externes:\n",
    "\n",
    "5. Si el token es troba en una llista de noms, organitzacions o localitzacions típiques\n",
    "\n",
    "Així que l'objectiu final del preprocessing seria transformar les dades importades perquè es converteixin en una tupla del token i uns llista de tres llistes de funcions, en primer lloc les bàsiques, en segon lloc les quatres primeres extres i en tercer lloc, les funcions de les llistes externes. Aquest format ens permetria més endavant activar i desactivar les funcions extres i el context usat de forma senzilla.\n",
    "\n",
    "Així que un cop establert els objectius del preprocessing i el format desitjat després d'aplicar el mateix, vam crear una sèrie de classes i funcions per aplicar-lo a les dades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\maxmg\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import nltk\n",
    "import json\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "class FuncPreprocessing:\n",
    "    def __init__(self, language='spanish'):\n",
    "        self._pattern = re.compile(r\"\\d\")\n",
    "        if language == 'spanish':\n",
    "            self.stop_words = set(nltk.corpus.stopwords.words('spanish'))\n",
    "        elif language == 'dutch':\n",
    "            self.stop_words = set(nltk.corpus.stopwords.words('dutch'))\n",
    "        elif language == 'english':\n",
    "            self.stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "        with open('hol_names.txt', 'r', encoding='utf-8') as file:\n",
    "            hol_names = [line.strip() for line in file.readlines()]\n",
    "        with open('esp_names.txt', 'r', encoding='utf-8') as file:\n",
    "            esp_names = [line.strip() for line in file.readlines()]\n",
    "        self.names = hol_names + esp_names\n",
    "\n",
    "        with open('countries.json', 'r', encoding='utf-8-sig') as file:\n",
    "            countries = json.load(file)['countries']\n",
    "        with open('cities.json', 'r', encoding='utf-8-sig') as file:\n",
    "            cities = json.load(file)['cities']\n",
    "        self.locations = [country['name'] for country in countries] + [city['name'] for city in cities]\n",
    "            \n",
    "\n",
    "    def __call__(self, corpus: List[List[tuple[str, str]]]) -> List[List[tuple[str, List[List[str]]]]]:\n",
    "        \"\"\"\n",
    "        Extract features from a corpus\n",
    "\n",
    "        :param corpus: list of list of tuples (word, tag)\n",
    "        :type corpus: list(list(tuple(str, str)))\n",
    "        :return: list of features\n",
    "        :rtype: list(list(list(str)))\n",
    "        \"\"\"\n",
    "        return [self.find_sent_features(sentence) for sentence in corpus]\n",
    "        \n",
    "    def find_sent_features(self, sentence):\n",
    "        \"\"\"\n",
    "        Extract features from a sentence\n",
    "\n",
    "        :param sentence: list of tuples (word, tag)\n",
    "        :type sentence: list(tuple(str, str))\n",
    "        :return: list of features\n",
    "        :rtype: list(list(str))\n",
    "        \"\"\"\n",
    "        new_sentence = []\n",
    "        for i in range(len(sentence)):\n",
    "            new_sentence.append(((sentence[i][0][0], self.get_token_features(sentence, i)), sentence[i][1]))\n",
    "        return new_sentence\n",
    "\n",
    "\n",
    "    def get_token_features(self, tokens, idx):\n",
    "        \"\"\"\n",
    "        Extract basic features and extra feature about this word including\n",
    "            - Current word\n",
    "            - is it capitalized?\n",
    "            - Does it have punctuation?\n",
    "            - Does it have a number?\n",
    "            - Suffixes up to length 3\n",
    "            - Prefixes up to length 3\n",
    "            - POS\n",
    "            - Word length\n",
    "            - Stop word\n",
    "            - Names\n",
    "            - Locations\n",
    "\n",
    "        :return: a list which contains the features\n",
    "        :rtype: list(list(str))\n",
    "        \"\"\"\n",
    "        token = tokens[idx][0]\n",
    "\n",
    "        feature_list = [[], [], []]\n",
    "\n",
    "        if not token[0]:\n",
    "            return feature_list\n",
    "\n",
    "        # Capitalization\n",
    "        if token[0][0].isupper():\n",
    "            feature_list[0].append(\"CAPITALIZATION\")\n",
    "\n",
    "        # Number\n",
    "        if re.search(self._pattern, token[0]) is not None:\n",
    "            feature_list[0].append(\"HAS_NUM\")\n",
    "\n",
    "        # Punctuation\n",
    "        punc_cat = {\"Pc\", \"Pd\", \"Ps\", \"Pe\", \"Pi\", \"Pf\", \"Po\"}\n",
    "        if all(unicodedata.category(x) in punc_cat for x in token[0]):\n",
    "            feature_list[0].append(\"PUNCTUATION\")\n",
    "\n",
    "        # Suffix up to length 3\n",
    "        if len(token[0]) > 1:\n",
    "            feature_list[0].append(\"SUF_\" + token[0][-1:])\n",
    "        if len(token[0]) > 2:\n",
    "            feature_list[0].append(\"SUF_\" + token[0][-2:])\n",
    "        if len(token[0]) > 3:\n",
    "            feature_list[0].append(\"SUF_\" + token[0][-3:])\n",
    "\n",
    "        # Word \n",
    "\n",
    "        feature_list[0].append(\"WORD_\" + token[0])\n",
    "\n",
    "        # Prefix up to length 3\n",
    "\n",
    "        # Prefixes of the word\n",
    "\n",
    "        prefixes = []\n",
    "        \n",
    "        if len(token[0]) > 1:\n",
    "            prefixes.append(\"PREF_\" + token[0][:1])\n",
    "        if len(token[0]) > 2:\n",
    "            prefixes.append(\"PREF_\" + token[0][:2])\n",
    "        if len(token[0]) > 3:\n",
    "            prefixes.append(\"PREF_\" + token[0][:3])\n",
    "\n",
    "        feature_list[1].append(prefixes)\n",
    "\n",
    "        #POS\n",
    "\n",
    "        feature_list[1].append(\"POS_\" + token[1])\n",
    "\n",
    "        # Word length\n",
    "\n",
    "        feature_list[1].append(\"WORD_LENGTH_\" + str(len(token[0])))\n",
    "\n",
    "        # Stop word\n",
    "\n",
    "        if token[0] in self.stop_words:\n",
    "            feature_list[1].append(\"STOP_WORD\")\n",
    "        else:\n",
    "            feature_list[1].append(None)\n",
    "\n",
    "        # If capitalized\n",
    "        if token[0][0].isupper():\n",
    "            # Names\n",
    "\n",
    "            if token[0] in self.names:\n",
    "                feature_list[2].append(\"NAME\")\n",
    "\n",
    "            # Locations\n",
    "\n",
    "            if token[0] in self.locations:\n",
    "                feature_list[2].append(\"LOCATION\")\n",
    "\n",
    "        return feature_list\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_train(corpus: List[List[tuple]], language = 'spanish') -> List[List[tuple]]:\n",
    "    '''\n",
    "    Preprocess the corpus for training\n",
    "\n",
    "    :param corpus: list of list of tuples (word, tag)\n",
    "    :type corpus: list(list(tuple(str, str)))\n",
    "    :return: list of features\n",
    "    :rtype: list(list(tuple(tuple(str, list(list(str))), str)))\n",
    "    '''\n",
    "    new_corpus = []\n",
    "    for sentence in corpus:\n",
    "        new_sentence = []\n",
    "        for word_tuple in sentence:\n",
    "            new_word_tuple = ((word_tuple[0], word_tuple[1]), word_tuple[2])\n",
    "            new_sentence.append(new_word_tuple)\n",
    "        new_corpus.append(new_sentence)\n",
    "    new_corpus = FuncPreprocessing(language)(new_corpus)\n",
    "    return new_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_token_tag(corpus: List[List[tuple]]) -> tuple[List[List[tuple]], List[List[str]]]:\n",
    "    '''\n",
    "    Separate the tokens and tags from the corpus\n",
    "    \n",
    "    :param corpus: list of list of tuples (word, tag)\n",
    "    :type corpus: list(list(tuple(tuple(str, list(list(str))), str)))\n",
    "    :return: tokens and tagsç\n",
    "    :rtype: list(list(tuple)), list(list(str))\n",
    "    '''\n",
    "    tokens = [[word[0] for word in sentence] for sentence in corpus]\n",
    "    tags = [[word[1] for word in sentence] for sentence in corpus]\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_test(corpus: List[List[tuple]]) ->tuple[List[List[tuple]], List[List[str]]]:\n",
    "    '''\n",
    "    Preprocess the corpus for testing\n",
    "    '''\n",
    "    corpus_prep = prep_train(corpus)\n",
    "    tokens, tags = sep_token_tag(corpus_prep)\n",
    "    return tokens, tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En les següents dues cel·les es mostra com eren les dades importades abans del preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sao', 'NC', 'B-LOC'),\n",
       " ('Paulo', 'VMI', 'I-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Brasil', 'NC', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('23', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFECOM', 'NP', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp_testa[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train = prep_train(esp_train)\n",
    "esp_testa_tokens, esp_testa_tags = prep_test(esp_testa)\n",
    "esp_testb_tokens, esp_testb_tags = prep_test(esp_testb)\n",
    "\n",
    "ned_train = prep_train(ned_train)\n",
    "ned_testa_tokens, ned_testa_tags = prep_test(ned_testa)\n",
    "ned_testb_tokens, ned_testb_tags = prep_test(ned_testb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En les tres següents cel·les es mostra com queden les dades importades després del preprocessing. Es pot observar que ara el token va acompanyat de les llistes de funcions. També es van separar els tags de les particions de test i validació, per poder comparar-les amb les predites pels models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Melbourne',\n",
       "   [['CAPITALIZATION', 'SUF_e', 'SUF_ne', 'SUF_rne', 'WORD_Melbourne'],\n",
       "    [['PREF_M', 'PREF_Me', 'PREF_Mel'], 'POS_NP', 'WORD_LENGTH_9', None],\n",
       "    ['LOCATION']]),\n",
       "  'B-LOC'),\n",
       " (('(',\n",
       "   [['PUNCTUATION', 'WORD_('], [[], 'POS_Fpa', 'WORD_LENGTH_1', None], []]),\n",
       "  'O'),\n",
       " (('Australia',\n",
       "   [['CAPITALIZATION', 'SUF_a', 'SUF_ia', 'SUF_lia', 'WORD_Australia'],\n",
       "    [['PREF_A', 'PREF_Au', 'PREF_Aus'], 'POS_NP', 'WORD_LENGTH_9', None],\n",
       "    ['LOCATION']]),\n",
       "  'B-LOC'),\n",
       " ((')',\n",
       "   [['PUNCTUATION', 'WORD_)'], [[], 'POS_Fpt', 'WORD_LENGTH_1', None], []]),\n",
       "  'O'),\n",
       " ((',',\n",
       "   [['PUNCTUATION', 'WORD_,'], [[], 'POS_Fc', 'WORD_LENGTH_1', None], []]),\n",
       "  'O'),\n",
       " (('25',\n",
       "   [['HAS_NUM', 'SUF_5', 'WORD_25'],\n",
       "    [['PREF_2'], 'POS_Z', 'WORD_LENGTH_2', None],\n",
       "    []]),\n",
       "  'O'),\n",
       " (('may',\n",
       "   [['SUF_y', 'SUF_ay', 'WORD_may'],\n",
       "    [['PREF_m', 'PREF_ma'], 'POS_NC', 'WORD_LENGTH_3', None],\n",
       "    []]),\n",
       "  'O'),\n",
       " (('(',\n",
       "   [['PUNCTUATION', 'WORD_('], [[], 'POS_Fpa', 'WORD_LENGTH_1', None], []]),\n",
       "  'O'),\n",
       " (('EFE',\n",
       "   [['CAPITALIZATION', 'SUF_E', 'SUF_FE', 'WORD_EFE'],\n",
       "    [['PREF_E', 'PREF_EF'], 'POS_NC', 'WORD_LENGTH_3', None],\n",
       "    []]),\n",
       "  'B-ORG'),\n",
       " ((')',\n",
       "   [['PUNCTUATION', 'WORD_)'], [[], 'POS_Fpt', 'WORD_LENGTH_1', None], []]),\n",
       "  'O'),\n",
       " (('.',\n",
       "   [['PUNCTUATION', 'WORD_.'], [[], 'POS_Fp', 'WORD_LENGTH_1', None], []]),\n",
       "  'O')]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Sao',\n",
       "  [['CAPITALIZATION', 'SUF_o', 'SUF_ao', 'WORD_Sao'],\n",
       "   [['PREF_S', 'PREF_Sa'], 'POS_NC', 'WORD_LENGTH_3', None],\n",
       "   ['NAME']]),\n",
       " ('Paulo',\n",
       "  [['CAPITALIZATION', 'SUF_o', 'SUF_lo', 'SUF_ulo', 'WORD_Paulo'],\n",
       "   [['PREF_P', 'PREF_Pa', 'PREF_Pau'], 'POS_VMI', 'WORD_LENGTH_5', None],\n",
       "   ['NAME', 'LOCATION']]),\n",
       " ('(',\n",
       "  [['PUNCTUATION', 'WORD_('], [[], 'POS_Fpa', 'WORD_LENGTH_1', None], []]),\n",
       " ('Brasil',\n",
       "  [['CAPITALIZATION', 'SUF_l', 'SUF_il', 'SUF_sil', 'WORD_Brasil'],\n",
       "   [['PREF_B', 'PREF_Br', 'PREF_Bra'], 'POS_NC', 'WORD_LENGTH_6', None],\n",
       "   ['LOCATION']]),\n",
       " (')',\n",
       "  [['PUNCTUATION', 'WORD_)'], [[], 'POS_Fpt', 'WORD_LENGTH_1', None], []]),\n",
       " (',', [['PUNCTUATION', 'WORD_,'], [[], 'POS_Fc', 'WORD_LENGTH_1', None], []]),\n",
       " ('23',\n",
       "  [['HAS_NUM', 'SUF_3', 'WORD_23'],\n",
       "   [['PREF_2'], 'POS_Z', 'WORD_LENGTH_2', None],\n",
       "   []]),\n",
       " ('may',\n",
       "  [['SUF_y', 'SUF_ay', 'WORD_may'],\n",
       "   [['PREF_m', 'PREF_ma'], 'POS_NC', 'WORD_LENGTH_3', None],\n",
       "   []]),\n",
       " ('(',\n",
       "  [['PUNCTUATION', 'WORD_('], [[], 'POS_Fpa', 'WORD_LENGTH_1', None], []]),\n",
       " ('EFECOM',\n",
       "  [['CAPITALIZATION', 'SUF_M', 'SUF_OM', 'SUF_COM', 'WORD_EFECOM'],\n",
       "   [['PREF_E', 'PREF_EF', 'PREF_EFE'], 'POS_NP', 'WORD_LENGTH_6', None],\n",
       "   []]),\n",
       " (')',\n",
       "  [['PUNCTUATION', 'WORD_)'], [[], 'POS_Fpt', 'WORD_LENGTH_1', None], []]),\n",
       " ('.', [['PUNCTUATION', 'WORD_.'], [[], 'POS_Fp', 'WORD_LENGTH_1', None], []])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp_testa_tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B-LOC', 'I-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "esp_testa_tags[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definició de GetFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per poder aprofitar aquest nou format de les dades, vam crear una classe que guardava com a variables de classe una sèrie de vectors i un booleà que indicaven quines funcions es volien o no utilitzar. El vector \"features_vector\" indica quina de les 4 primeres funcions extra s'utilitza. El booleà \"lists\" indica si s'utilitzen o no les llistes externes. I finalment, \"word_vector\" indica quin context de la paraula s'utilitza, permetent com a màxim dues paraules endavant i dues paraules enrere.\n",
    "\n",
    "Les dues primeres estructures, \"features_vector\" i \"lists\", s'utilitzarien en aquest primer bloc de la pràctica, el de definir les funcions. I \"word_vector\" es va utilitzar en el segon bloc, el del context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetFeatures:\n",
    "            \n",
    "    def __init__(self, features_vector = [0, 0, 0, 0], lists = False , word_vector = [0, 0, 1, 0, 0]):\n",
    "            self.features_vector = features_vector\n",
    "            self.lists = lists\n",
    "            self.word_vector = word_vector\n",
    "\n",
    "    def __call__(self, tokens: List[tuple[str, List[List[str]]]], idx: int) -> List[str]:\n",
    "        '''\n",
    "        Extract features from a token\n",
    "        \n",
    "        :param tokens: list of tuples (word, features)\n",
    "        :type tokens: list(tuple(str, list(list(str))))\n",
    "        :param idx: index of the token\n",
    "        :type idx: int\n",
    "        :return: list of features\n",
    "        :rtype: list(str)\n",
    "        '''\n",
    "        feature_list = []\n",
    "\n",
    "        if not tokens[idx][0]:\n",
    "            return feature_list\n",
    "\n",
    "        if self.word_vector[2] == 1:\n",
    "            features = tokens[idx][1]\n",
    "\n",
    "            for feat in features[0]:\n",
    "                feature_list.append(feat)\n",
    "\n",
    "            if self.features_vector[0] == 1:\n",
    "                for pre in features[1][0]:\n",
    "                    feature_list.append(pre)\n",
    "            if self.features_vector[1] == 1:\n",
    "                feature_list.append(features[1][1])\n",
    "            if self.features_vector[2] == 1:\n",
    "                feature_list.append(features[1][2])\n",
    "            if self.features_vector[3] == 1:\n",
    "                if features[1][3]:\n",
    "                    feature_list.append(features[1][3])\n",
    "\n",
    "            if self.lists:\n",
    "                for feat in features[2]:\n",
    "                    feature_list.append(feat)\n",
    "            \n",
    "        if idx > 1 and self.word_vector[0] == 1:\n",
    "            features = tokens[idx - 2][1]\n",
    "\n",
    "            for feat in features[0]:\n",
    "                feature_list.append(\"2PREV\" + feat)\n",
    "\n",
    "            if self.features_vector[0] == 1:\n",
    "                for pre in features[1][0]:\n",
    "                    feature_list.append(\"2PREV\" + pre)\n",
    "            if self.features_vector[1] == 1:\n",
    "                feature_list.append(\"2PREV\" + features[1][1])\n",
    "            if self.features_vector[2] == 1:\n",
    "                feature_list.append(\"2PREV\" + features[1][2])\n",
    "            if self.features_vector[3] == 1:\n",
    "                if features[1][3]:\n",
    "                    feature_list.append(\"2PREV\" + features[1][3])\n",
    "\n",
    "            if self.lists:\n",
    "                for feat in features[2]:\n",
    "                    feature_list.append(\"2PREV\" + feat)\n",
    "\n",
    "        if idx > 0 and self.word_vector[1] == 1:\n",
    "            features = tokens[idx - 1][1]\n",
    "\n",
    "            for feat in features[0]:\n",
    "                feature_list.append(\"PREV\" + feat)\n",
    "\n",
    "            if self.features_vector[0] == 1:\n",
    "                for pre in features[1][0]:\n",
    "                    feature_list.append(\"PREV\" + pre)\n",
    "            if self.features_vector[1] == 1:\n",
    "                feature_list.append(\"PREV\" + features[1][1])\n",
    "            if self.features_vector[2] == 1:\n",
    "                feature_list.append(\"PREV\" + features[1][2])\n",
    "            if self.features_vector[3] == 1:\n",
    "                if features[1][3]:\n",
    "                    feature_list.append(\"PREV\" + features[1][3])\n",
    "\n",
    "            if self.lists:\n",
    "                for feat in features[2]:\n",
    "                    feature_list.append(\"PREV\" + feat)\n",
    "\n",
    "        if idx < len(tokens) - 1 and self.word_vector[3] == 1:\n",
    "            features = tokens[idx + 1][1]\n",
    "\n",
    "            for feat in features[0]:\n",
    "                feature_list.append(\"NEXT\" + feat)\n",
    "\n",
    "            if self.features_vector[0] == 1:\n",
    "                for pre in features[1][0]:\n",
    "                    feature_list.append(\"NEXT\" + pre)\n",
    "            if self.features_vector[1] == 1:\n",
    "                feature_list.append(\"NEXT\" + features[1][1])\n",
    "            if self.features_vector[2] == 1:\n",
    "                feature_list.append(\"NEXT\" + features[1][2])\n",
    "            if self.features_vector[3] == 1:\n",
    "                if features[1][3]:\n",
    "                    feature_list.append(\"NEXT\" + features[1][3])\n",
    "\n",
    "            if self.lists:\n",
    "                for feat in features[2]:\n",
    "                    feature_list.append(\"NEXT\" + feat)\n",
    "\n",
    "        if idx < len(tokens) - 2 and self.word_vector[4] == 1:\n",
    "            features = tokens[idx + 2][1]\n",
    "\n",
    "            for feat in features[0]:\n",
    "                feature_list.append(\"2NEXT\" + feat)\n",
    "\n",
    "            if self.features_vector[0] == 1:\n",
    "                for pre in features[1][0]:\n",
    "                    feature_list.append(\"2NEXT\" + pre)\n",
    "            if self.features_vector[1] == 1:\n",
    "                feature_list.append(\"2NEXT\" + features[1][1])\n",
    "            if self.features_vector[2] == 1:\n",
    "                feature_list.append(\"2NEXT\" + features[1][2])\n",
    "            if self.features_vector[3] == 1:\n",
    "                if features[1][3]:\n",
    "                    feature_list.append(\"2NEXT\" + features[1][3])\n",
    "\n",
    "            if self.lists:\n",
    "                for feat in features[2]:\n",
    "                    feature_list.append(\"2NEXT\" + feat)\n",
    "\n",
    "        return feature_list\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funció d'avaluació d'un model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Abans de començar a definir i experimentar amb les \"features functions\" i el context, era necessari establir un criteri de avaluació pels nostres models. En un primer lloc el vam establir per la codificació BIO, però més endavant el modificaríem per comparar les diferents codificacions.\n",
    "\n",
    "Vam estar valorant diferents mètriques que ens aportessin informació real del rendiment del model. Al final vam decidir treballar amb dos enfocaments per poder valorar més correctament els models.\n",
    "\n",
    "En primer lloc, vam considerar la \"accuracy\" balancejada, que ens servia per veure quantes etiquetes predites eren correctes. Per més endavant poder comparar entre codificacions, els \"tags\" real i predits es transformen, en primer lloc, a IO. També s'eliminen les categories d'entitats, i llavors es calcula la mètrica. Aquesta decisió la vam prendre amb la idea que aquesta mètrica valores essencialment la capacitat del model d'identificar entitats, no el seu tipus, ja que el tipus ja el tindríem més en compte a les altres mètriques (les explicades en el següent paràgraf). Vam decidir fer la \"accuracy\" balancejada pel fet que hi ha molta més quantitat de \"O\" en les frases. Com s'ha dit, aquesta mètrica ens va permetre valorar el rendiment del model a l'hora d'identificar \"tags\" individuals i sense importar el tipus. Sabíem que no era una mètrica que pogués, per ella sola, valorar correctament el model, però sí que cobria una part important.\n",
    "\n",
    "Per complementar-la, vam decidir també fer un estudi de les entitats, no de les etiquetes. Amb diverses funcions vam aconseguir localitzar totes les entitats des de les etiquetes, i comparant les entitats reals amb les predites, vam poder extreure molta informació: quin percentatge d'entitats es detecten a la perfecció; quin percentatge de cada tipus d'entitats detecta correctament; i quantes entitats que realment no ho són \"s'inventa\" el model. Juntament amb la \"accuracy\" balancejada ens semblaven una sèrie de dades que permetien valorar a la perfecció el rendiment dels models.\n",
    "\n",
    "Al final el criteri que vam seguir és donar-li més valor a detectar entitats perfectament, ja que és realment la tasca del model. A continuació es troben totes les funcions que conformen la funció de avaluació final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_tags_to_IO(sent_tags):\n",
    "    '''\n",
    "    Convert sentence tags to IO format\n",
    "    \n",
    "    :param sent_tags: list of tags\n",
    "    :type sent_tags: list(str)\n",
    "    :return: list of IO tags\n",
    "    :rtype: list(str)\n",
    "    '''\n",
    "    io_sent_tags = []\n",
    "    for sent in sent_tags:\n",
    "        tags = [re.sub(r'\\b[BES]-', 'I-', tag) for tag in sent]\n",
    "        io_sent_tags.append(tags)\n",
    "    return io_sent_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entity_finder(sent_tags):\n",
    "    '''\n",
    "    Find entities in a sentence\n",
    "\n",
    "    :param sent_tags: list of tags\n",
    "    :type sent_tags: list(str)\n",
    "    :return: list of entities\n",
    "    :rtype: list(tuple(str, tuple(int, int)))\n",
    "    '''\n",
    "    sent_tags_io = sent_tags_to_IO(sent_tags)\n",
    "\n",
    "    entities = []\n",
    "    for sent in sent_tags_io:\n",
    "        sent_entities = []\n",
    "        last = sent[0]\n",
    "        ini = None\n",
    "        end = None\n",
    "        type_ent = None\n",
    "        if last[0] == 'I':\n",
    "            ini = 0\n",
    "            end = 0\n",
    "            type_ent = last[2:]\n",
    "        for i in range(1, len(sent)):\n",
    "            tag = sent[i]\n",
    "            if tag[0] == 'I':\n",
    "                if last == 'O':\n",
    "                    ini = i\n",
    "                    end = i\n",
    "                    type_ent = tag[2:]\n",
    "                if last[0] == 'I':\n",
    "                    end = i\n",
    "                last = tag\n",
    "            else:\n",
    "                if last[0] == 'I':\n",
    "                    sent_entities.append((type_ent, (ini, end)))\n",
    "                    ini = None\n",
    "                    end = None\n",
    "                    type_ent = None\n",
    "                last = tag\n",
    "        if ini:\n",
    "            sent_entities.append((type_ent, (ini, end)))\n",
    "        entities.append(sent_entities)\n",
    "\n",
    "    return entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from collections import Counter\n",
    "\n",
    "def evaluate_tagger_performance(sent_real, sent_pred, features = [0,0,0,0], errors = False):\n",
    "    '''\n",
    "    Evaluate the performance of a tagger\n",
    "\n",
    "    :param sent_real: list of real tags\n",
    "    :type sent_real: list(list(str))\n",
    "    :param sent_pred: list of predicted tags\n",
    "    :type sent_pred: list(list(str))\n",
    "    :param features: list of features to use\n",
    "    :type features: list(int)\n",
    "    :param errors: return errors\n",
    "    :type errors: bool\n",
    "    '''\n",
    "\n",
    "    info = {'Codification': features, 'Balanced accuracy': 0, 'Total entities': 0, 'Entities correct': 0, 'LOC correct': 0, 'MISC correct': 0, 'ORG correct': 0, 'PER correct': 0, 'Entities invented': 0}\n",
    "    \n",
    "    sent_io_real = sent_tags_to_IO(sent_real)\n",
    "    sent_io_pred = sent_tags_to_IO(sent_pred)\n",
    "\n",
    "    def join_sent_tags(sent_tags):\n",
    "        return [tag[0] for sent in sent_tags for tag in sent]\n",
    "\n",
    "    # Calcula la precisión balanceada\n",
    "    info['Balanced accuracy'] = balanced_accuracy_score(join_sent_tags(sent_io_real), join_sent_tags(sent_io_pred))\n",
    "\n",
    "    real_entities = entity_finder(sent_io_real)\n",
    "    pred_entities = entity_finder(sent_io_pred)\n",
    "\n",
    "    total_ent = 0\n",
    "    total_loc = 0\n",
    "    total_misc = 0\n",
    "    total_org = 0\n",
    "    total_per = 0\n",
    "\n",
    "    for sent in real_entities:\n",
    "        for entity in sent:\n",
    "            total_ent += 1\n",
    "            if entity[0] == 'LOC':\n",
    "                total_loc += 1\n",
    "            if entity[0] == 'MISC':\n",
    "                total_misc += 1\n",
    "            if entity[0] =='ORG':\n",
    "                total_org += 1\n",
    "            if entity[0] == 'PER':\n",
    "                total_per += 1\n",
    "\n",
    "    info['Total entities'] = total_ent\n",
    "\n",
    "    good_ent = 0\n",
    "    good_loc = 0\n",
    "    good_misc = 0\n",
    "    good_org = 0\n",
    "    good_per = 0\n",
    "    invented_ent = 0\n",
    "\n",
    "    for i in range(0, len(real_entities)):\n",
    "        for entity in pred_entities[i]:\n",
    "            if entity in real_entities[i]:\n",
    "                good_ent += 1\n",
    "                if entity[0] == 'LOC':\n",
    "                    good_loc += 1\n",
    "                if entity[0] == 'MISC':\n",
    "                    good_misc += 1\n",
    "                if entity[0] =='ORG':\n",
    "                    good_org += 1\n",
    "                if entity[0] == 'PER':\n",
    "                    good_per += 1\n",
    "            else:\n",
    "                invented_ent += 1\n",
    "\n",
    "    info['Entities correct'] = good_ent/total_ent\n",
    "    info['LOC correct'] = good_loc/total_loc\n",
    "    info['MISC correct'] = good_misc/total_misc\n",
    "    info['ORG correct'] = good_org/total_org\n",
    "    info['PER correct'] = good_per/total_per\n",
    "\n",
    "    info['Entities invented'] = invented_ent\n",
    "\n",
    "    if errors:\n",
    "        errors = []\n",
    "        invented = []\n",
    "        for i in range(0, len(real_entities)):\n",
    "            for entity in pred_entities[i]:\n",
    "                if entity not in real_entities[i]:\n",
    "                    errors.append((i, entity))\n",
    "        for i in range(0, len(pred_entities)):\n",
    "            for entity in real_entities[i]:\n",
    "                if entity not in pred_entities[i]:\n",
    "                    invented.append((i, entity))\n",
    "        return info, errors, invented\n",
    "                \n",
    "    return info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search per definir les quatre primeres funcions extres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop definit un criteri d'avaluació, vam decidir fer un \"grid search\" per seleccionar quines de les quatre primeres funcions extres utilitzaríem. Un petit recordatori de les quatre funcions:\n",
    "\n",
    "1 - Prefixos\n",
    "2 - Pos-Tag\n",
    "3 - Longitud\n",
    "4 - Stop-Word\n",
    "\n",
    "Gràcies a l'eficiència i flexibilitat que ens proporcionava el \"preprocessing\" fet i la classe \"GetFeatures\" vam decidir provar totes les combinacions d'aquestes funcions possibles, i crear una taula per cada idioma amb els resultats. Després analitzaríem les mètriques i decidiríem quina combinació prendre, encara que esperàvem que en els dos casos fos la combinació de les quatre \"feature functions\".\n",
    "\n",
    "Vam crear una funció que fes aquest \"grid search\", i la vam aplicar als dos idiomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import itertools\n",
    "import nltk\n",
    "\n",
    "def features_grid_search(train, val_tokens, val_tags):\n",
    "    '''\n",
    "    Perform a grid search over the features\n",
    "    '''\n",
    "    feature_combinations = list(itertools.product([0, 1], repeat=4))\n",
    "\n",
    "    results = pd.DataFrame(columns=['Features', 'Balanced accuracy', 'Total entities', 'Entities correct', 'LOC correct', 'MISC correct', 'ORG correct', 'PER correct', 'Entities invented'])\n",
    "\n",
    "    # Para cada combinación de características\n",
    "    for features in feature_combinations:\n",
    "        model = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=features))\n",
    "        model.train(train, 'crfTagger.mdl')\n",
    "        prediction = model.tag_sents(val_tokens)\n",
    "\n",
    "        _, prediction_tags = sep_token_tag(prediction)\n",
    "\n",
    "        feat_results = evaluate_tagger_performance(val_tags, prediction_tags, features)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame([feat_results])], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de \"feature functions\" en el model de l'idioma espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = features_grid_search(esp_train, esp_testa_tokens, esp_testa_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "      <td>0.961174</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.677585</td>\n",
       "      <td>0.741834</td>\n",
       "      <td>0.471655</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>0.707602</td>\n",
       "      <td>1165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>0.960965</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.674310</td>\n",
       "      <td>0.744995</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.666864</td>\n",
       "      <td>0.704261</td>\n",
       "      <td>1176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>0.961637</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.674310</td>\n",
       "      <td>0.742887</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>0.656194</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>1188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 0, 1, 1)</td>\n",
       "      <td>0.961802</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.674544</td>\n",
       "      <td>0.742887</td>\n",
       "      <td>0.458050</td>\n",
       "      <td>0.656787</td>\n",
       "      <td>0.725146</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>0.966648</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.691390</td>\n",
       "      <td>0.763962</td>\n",
       "      <td>0.467120</td>\n",
       "      <td>0.684647</td>\n",
       "      <td>0.725982</td>\n",
       "      <td>1168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 1, 0, 1)</td>\n",
       "      <td>0.966934</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.690688</td>\n",
       "      <td>0.765016</td>\n",
       "      <td>0.462585</td>\n",
       "      <td>0.682276</td>\n",
       "      <td>0.727652</td>\n",
       "      <td>1173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 1, 1, 0)</td>\n",
       "      <td>0.966351</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.690688</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.682869</td>\n",
       "      <td>0.740184</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0, 1, 1, 1)</td>\n",
       "      <td>0.966626</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.691858</td>\n",
       "      <td>0.749210</td>\n",
       "      <td>0.464853</td>\n",
       "      <td>0.683462</td>\n",
       "      <td>0.741855</td>\n",
       "      <td>1175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>0.962893</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.692326</td>\n",
       "      <td>0.775553</td>\n",
       "      <td>0.462585</td>\n",
       "      <td>0.676941</td>\n",
       "      <td>0.732665</td>\n",
       "      <td>1135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 0, 0, 1)</td>\n",
       "      <td>0.962232</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.690454</td>\n",
       "      <td>0.772392</td>\n",
       "      <td>0.453515</td>\n",
       "      <td>0.673977</td>\n",
       "      <td>0.736007</td>\n",
       "      <td>1140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1, 0, 1, 0)</td>\n",
       "      <td>0.962772</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.696537</td>\n",
       "      <td>0.773446</td>\n",
       "      <td>0.487528</td>\n",
       "      <td>0.678720</td>\n",
       "      <td>0.737678</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1, 0, 1, 1)</td>\n",
       "      <td>0.963201</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.697239</td>\n",
       "      <td>0.772392</td>\n",
       "      <td>0.482993</td>\n",
       "      <td>0.684647</td>\n",
       "      <td>0.734336</td>\n",
       "      <td>1129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1, 1, 0, 0)</td>\n",
       "      <td>0.967012</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.702620</td>\n",
       "      <td>0.776607</td>\n",
       "      <td>0.469388</td>\n",
       "      <td>0.691168</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>1132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1, 1, 0, 1)</td>\n",
       "      <td>0.966880</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.703556</td>\n",
       "      <td>0.777661</td>\n",
       "      <td>0.471655</td>\n",
       "      <td>0.691761</td>\n",
       "      <td>0.746867</td>\n",
       "      <td>1128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1, 1, 1, 0)</td>\n",
       "      <td>0.967353</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.704960</td>\n",
       "      <td>0.777661</td>\n",
       "      <td>0.478458</td>\n",
       "      <td>0.690575</td>\n",
       "      <td>0.751044</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1, 1, 1, 1)</td>\n",
       "      <td>0.967331</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.705194</td>\n",
       "      <td>0.775553</td>\n",
       "      <td>0.478458</td>\n",
       "      <td>0.692353</td>\n",
       "      <td>0.751044</td>\n",
       "      <td>1126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Features  Balanced accuracy Total entities  Entities correct  \\\n",
       "0   (0, 0, 0, 0)           0.961174           4274          0.677585   \n",
       "1   (0, 0, 0, 1)           0.960965           4274          0.674310   \n",
       "2   (0, 0, 1, 0)           0.961637           4274          0.674310   \n",
       "3   (0, 0, 1, 1)           0.961802           4274          0.674544   \n",
       "4   (0, 1, 0, 0)           0.966648           4274          0.691390   \n",
       "5   (0, 1, 0, 1)           0.966934           4274          0.690688   \n",
       "6   (0, 1, 1, 0)           0.966351           4274          0.690688   \n",
       "7   (0, 1, 1, 1)           0.966626           4274          0.691858   \n",
       "8   (1, 0, 0, 0)           0.962893           4274          0.692326   \n",
       "9   (1, 0, 0, 1)           0.962232           4274          0.690454   \n",
       "10  (1, 0, 1, 0)           0.962772           4274          0.696537   \n",
       "11  (1, 0, 1, 1)           0.963201           4274          0.697239   \n",
       "12  (1, 1, 0, 0)           0.967012           4274          0.702620   \n",
       "13  (1, 1, 0, 1)           0.966880           4274          0.703556   \n",
       "14  (1, 1, 1, 0)           0.967353           4274          0.704960   \n",
       "15  (1, 1, 1, 1)           0.967331           4274          0.705194   \n",
       "\n",
       "    LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0      0.741834      0.471655     0.673977     0.707602              1165  \n",
       "1      0.744995      0.469388     0.666864     0.704261              1176  \n",
       "2      0.742887      0.458050     0.656194     0.725146              1188  \n",
       "3      0.742887      0.458050     0.656787     0.725146              1185  \n",
       "4      0.763962      0.467120     0.684647     0.725982              1168  \n",
       "5      0.765016      0.462585     0.682276     0.727652              1173  \n",
       "6      0.749210      0.460317     0.682869     0.740184              1180  \n",
       "7      0.749210      0.464853     0.683462     0.741855              1175  \n",
       "8      0.775553      0.462585     0.676941     0.732665              1135  \n",
       "9      0.772392      0.453515     0.673977     0.736007              1140  \n",
       "10     0.773446      0.487528     0.678720     0.737678              1127  \n",
       "11     0.772392      0.482993     0.684647     0.734336              1129  \n",
       "12     0.776607      0.469388     0.691168     0.746032              1132  \n",
       "13     0.777661      0.471655     0.691761     0.746867              1128  \n",
       "14     0.777661      0.478458     0.690575     0.751044              1125  \n",
       "15     0.775553      0.478458     0.692353     0.751044              1126  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop creada la taula de resultats de totes les combinacions de l'idioma espanyol, vam procedir a fer una anàlisi dels resultats.\n",
    "\n",
    "Primerament, observant la \"balanced accuracy\" vam poder comprovar que en tots el casos el model ubica bastant bé on hi ha entitats, ja que tots els resultats són majors al 0.96. Però en visualitzar les altres mètriques vam veure que no són tan bons a l'hora de detectar perfectament la ubicació i el tipus de l'entitat. Com que vam imaginar que seria una cosa recurrent fins i tot en el model final, vam decidir que més endavant analitzaríem alguns casos reals per entendre en quin sentit perdia tanta precisió en el tipus i en quins casos s'estava equivocant.\n",
    "\n",
    "Seguint en el mateix tema, també vam observar que el marge de millora es situava en el fet de detectar correctament les entitats i el seu tipus. Mentres en la \"accuracy\" la millora màxima és d'aproximadament 0.007, en el percentatge d'entitats correctes la millora màxima és de més o menys 0.03. Això ens va fer pensar que les noves \"feature functions\" estaven ajudant el model a detectar amb més precisió el tipus i posició exacte de l'entitat.\n",
    "\n",
    "Ja entrant més específicament en les combinacions, primer vam observar com milloraven les funcions de forma individual, és a dir, quan només s'activaven elles. Ens vam centrar a veure com millorava el percentatge d'entitats correctes. Les funcions que més milloraven el model eren els prefixos i el Pos-Tag. En canvi, les altres dues, no només no milloraven, sinó que feien lleugerament pitjor al model.\n",
    "\n",
    "Ja fixant-nos amb les combinacions, vam veure que la tercera funció, la longitud, si aportava un millora en els models amb més funcions actives, però les Stop-Words no estaven aportant pràcticament res, així que vam decidir no agafar-la. Per tant, la nostra combinació de funcions extres per l'espanyol va ser la [1, 1, 1, 0].\n",
    "\n",
    "També per comentar-ho, tots els models en general inventen bastantes entitats, però sí que, normalment, a mesura que s'activen funcions es va reduint el nombre de entitats inventades. En general, tots els tipus milloren o empitjoren en relació amb el total d'entitats, no sembla que hi hagi funciono que potenciïn sobretot un tipus d'entitat. Sí que es pot apreciar clarament que el tipus MISC és el que pitjor es detecta. Al final té sentit, ja que és el tipus més obert, que cobreix les restes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de \"feature functions\" en el model de l'idioma holandés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results2 = features_grid_search(ned_train, ned_testa_tokens, ned_testa_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(0, 0, 0, 0)</td>\n",
       "      <td>0.938590</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.576450</td>\n",
       "      <td>0.570787</td>\n",
       "      <td>0.580451</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.705281</td>\n",
       "      <td>772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(0, 0, 0, 1)</td>\n",
       "      <td>0.938291</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.575132</td>\n",
       "      <td>0.570787</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.445596</td>\n",
       "      <td>0.701874</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(0, 0, 1, 0)</td>\n",
       "      <td>0.949600</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.592707</td>\n",
       "      <td>0.602247</td>\n",
       "      <td>0.615038</td>\n",
       "      <td>0.433506</td>\n",
       "      <td>0.717206</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(0, 0, 1, 1)</td>\n",
       "      <td>0.950199</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.590510</td>\n",
       "      <td>0.597753</td>\n",
       "      <td>0.615038</td>\n",
       "      <td>0.426598</td>\n",
       "      <td>0.718910</td>\n",
       "      <td>833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(0, 1, 0, 0)</td>\n",
       "      <td>0.960987</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.609842</td>\n",
       "      <td>0.608989</td>\n",
       "      <td>0.633083</td>\n",
       "      <td>0.442142</td>\n",
       "      <td>0.749574</td>\n",
       "      <td>751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(0, 1, 0, 1)</td>\n",
       "      <td>0.960448</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.609842</td>\n",
       "      <td>0.608989</td>\n",
       "      <td>0.634586</td>\n",
       "      <td>0.442142</td>\n",
       "      <td>0.747871</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(0, 1, 1, 0)</td>\n",
       "      <td>0.964428</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.614675</td>\n",
       "      <td>0.613483</td>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.752981</td>\n",
       "      <td>786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(0, 1, 1, 1)</td>\n",
       "      <td>0.964832</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.615114</td>\n",
       "      <td>0.613483</td>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.430052</td>\n",
       "      <td>0.754685</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(1, 0, 0, 0)</td>\n",
       "      <td>0.939034</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.618190</td>\n",
       "      <td>0.638202</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.504318</td>\n",
       "      <td>0.746167</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(1, 0, 0, 1)</td>\n",
       "      <td>0.941577</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.617311</td>\n",
       "      <td>0.638202</td>\n",
       "      <td>0.590977</td>\n",
       "      <td>0.504318</td>\n",
       "      <td>0.742760</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(1, 0, 1, 0)</td>\n",
       "      <td>0.950807</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.637961</td>\n",
       "      <td>0.622472</td>\n",
       "      <td>0.645113</td>\n",
       "      <td>0.525043</td>\n",
       "      <td>0.752981</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>(1, 0, 1, 1)</td>\n",
       "      <td>0.950673</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.634007</td>\n",
       "      <td>0.622472</td>\n",
       "      <td>0.645113</td>\n",
       "      <td>0.511226</td>\n",
       "      <td>0.751278</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>(1, 1, 0, 0)</td>\n",
       "      <td>0.957044</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.636643</td>\n",
       "      <td>0.647191</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.509499</td>\n",
       "      <td>0.771721</td>\n",
       "      <td>755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(1, 1, 0, 1)</td>\n",
       "      <td>0.957164</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.636204</td>\n",
       "      <td>0.644944</td>\n",
       "      <td>0.621053</td>\n",
       "      <td>0.509499</td>\n",
       "      <td>0.771721</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(1, 1, 1, 0)</td>\n",
       "      <td>0.963677</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.653339</td>\n",
       "      <td>0.624719</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.530225</td>\n",
       "      <td>0.785349</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>(1, 1, 1, 1)</td>\n",
       "      <td>0.963677</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.652900</td>\n",
       "      <td>0.624719</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.785349</td>\n",
       "      <td>681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Features  Balanced accuracy Total entities  Entities correct  \\\n",
       "0   (0, 0, 0, 0)           0.938590           2276          0.576450   \n",
       "1   (0, 0, 0, 1)           0.938291           2276          0.575132   \n",
       "2   (0, 0, 1, 0)           0.949600           2276          0.592707   \n",
       "3   (0, 0, 1, 1)           0.950199           2276          0.590510   \n",
       "4   (0, 1, 0, 0)           0.960987           2276          0.609842   \n",
       "5   (0, 1, 0, 1)           0.960448           2276          0.609842   \n",
       "6   (0, 1, 1, 0)           0.964428           2276          0.614675   \n",
       "7   (0, 1, 1, 1)           0.964832           2276          0.615114   \n",
       "8   (1, 0, 0, 0)           0.939034           2276          0.618190   \n",
       "9   (1, 0, 0, 1)           0.941577           2276          0.617311   \n",
       "10  (1, 0, 1, 0)           0.950807           2276          0.637961   \n",
       "11  (1, 0, 1, 1)           0.950673           2276          0.634007   \n",
       "12  (1, 1, 0, 0)           0.957044           2276          0.636643   \n",
       "13  (1, 1, 0, 1)           0.957164           2276          0.636204   \n",
       "14  (1, 1, 1, 0)           0.963677           2276          0.653339   \n",
       "15  (1, 1, 1, 1)           0.963677           2276          0.652900   \n",
       "\n",
       "    LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0      0.570787      0.580451     0.445596     0.705281               772  \n",
       "1      0.570787      0.578947     0.445596     0.701874               773  \n",
       "2      0.602247      0.615038     0.433506     0.717206               834  \n",
       "3      0.597753      0.615038     0.426598     0.718910               833  \n",
       "4      0.608989      0.633083     0.442142     0.749574               751  \n",
       "5      0.608989      0.634586     0.442142     0.747871               747  \n",
       "6      0.613483      0.654135     0.430052     0.752981               786  \n",
       "7      0.613483      0.654135     0.430052     0.754685               785  \n",
       "8      0.638202      0.590977     0.504318     0.746167               679  \n",
       "9      0.638202      0.590977     0.504318     0.742760               700  \n",
       "10     0.622472      0.645113     0.525043     0.752981               728  \n",
       "11     0.622472      0.645113     0.511226     0.751278               738  \n",
       "12     0.647191      0.621053     0.509499     0.771721               755  \n",
       "13     0.644944      0.621053     0.509499     0.771721               758  \n",
       "14     0.624719      0.663158     0.530225     0.785349               680  \n",
       "15     0.624719      0.663158     0.528497     0.785349               681  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després d'analitzar els resultats en l'idioma espanyol, vam procedir a fer el mateix amb l'holandès. I ràpidament vam veure diferències i similituds importants.\n",
    "\n",
    "El que vam veure més ràpidament i més ens va sobtar va ser la precisió en els diferents tipus d'entitat. MISC, que en l'espanyol era clarament la pitjor, ara es prediu molt millor, quedant per sobre de LOC i ORG, sent aquesta última la pitjor amb diferència.\n",
    "\n",
    "També vam observar clarament dues coses. La primera és que, igual que abans, la \"accuracy\" balancejada era molt alta i la poca precisió residia en detectar a la perfecció les entitats. Però, en segon lloc, vam veure que ara el rang de millor en ambdós casos era molt superior, sent aproximadament com a màxim de 0.03 i 0.08 respectivament. Per tant, ara les funcions estaven millorant més els models.\n",
    "\n",
    "Quant a les funcions individuals, els resultats van ser semblant que a l'espanyol. Ara, individualment, la funció 3 si millora una mica, però la 4 segueix abans que igual. La 1 i la 2 segueixen sent les que tenen més impacte.\n",
    "\n",
    "Finalment, en les combinacions vam poder extreure les mateixes conclusions. La longitud si aporta però les Stop-Words no. Així que vam decidir prendre la mateixa combinació que amb l'espanyol, el vector [1, 1, 1, 0].\n",
    "\n",
    "Com a comentari final, en aquest idioma també hi ha un alt nombre d'entitats inventades, que baixen a l'hora d'afegir funcions. Quant a proporció amb el total d'entitats que hi ha, el resultat és semblant a l'idioma espanyol."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prova d'afegir llistes externes de noms i localitzacions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Per acabar de tancar aquest bloc, vam decidir afegir també la cinquena funció extra, la relacionada amb llistes. Per provar simplement vam comparar els dos models seleccionats a l'apartat anterior amb ells mateixos però afegint les llistes de noms i localitzacions. Aquestes funcions ja venien calculades al preprocessament, però ara expliquem quines llistes vam utilitzar.\n",
    "\n",
    "Vam decidir afegir noms i localitzacions, ja que ens semblava el més recurrent i típic i fàcil de repetir-se.\n",
    "\n",
    "Pels noms vam buscar noms espanyols i holandesos. Vam trobar dos repositoris de Git-Hub on hi havia arxius amb noms, en un cas espanyols, i en l'altre cas holandesos. A continuació els enllaços:\n",
    "\n",
    "Espanyol ---> https://github.com/olea/lemarios/blob/master/nombres-propios-es.txt\n",
    "\n",
    "Holandès ---> https://github.com/digitalheir/family-names-in-the-netherlands/blob/master/family_names_freq_5_or_more.lst\n",
    "\n",
    "Per les localitzacions també vam usar un repositori que contenia noms de països i ciutats en format JSON. A continuació l'enllaç:\n",
    "\n",
    "https://github.com/millan2993/countries/tree/master/json\n",
    "\n",
    "Tots els arxius utilitzats es troben a l'arxiu comprimit entregat.\n",
    "\n",
    "Per provar i fer la comparació dels models es va crear una funció que executava el model amb llistes i sense. Després vam analitzar els resultats per cada idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_comparation(train, val_tokens, val_tags):\n",
    "    '''\n",
    "    Compare the performance of the tagger with and without lists\n",
    "    '''\n",
    "    results = pd.DataFrame(columns=['Lists', 'Balanced accuracy', 'Total entities', 'Entities correct', 'LOC correct', 'MISC correct', 'ORG correct', 'PER correct', 'Entities invented'])\n",
    "\n",
    "    model = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=False))\n",
    "    model.train(train, 'crfTagger.mdl')\n",
    "    prediction = model.tag_sents(val_tokens)\n",
    "\n",
    "    _, prediction_tags = sep_token_tag(prediction)\n",
    "\n",
    "    feat_results = evaluate_tagger_performance(val_tags, prediction_tags, \"No lists\")\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([feat_results])], ignore_index=True)\n",
    "\n",
    "    model = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=True))\n",
    "    model.train(train, 'crfTagger.mdl')\n",
    "    prediction = model.tag_sents(val_tokens)\n",
    "\n",
    "    _, prediction_tags = sep_token_tag(prediction)\n",
    "\n",
    "    feat_results = evaluate_tagger_performance(val_tags, prediction_tags, \"Lists\")\n",
    "\n",
    "    results = pd.concat([results, pd.DataFrame([feat_results])], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de l'afegit de llistes externes als dos models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "results3 = list_comparation(esp_train, esp_testa_tokens, esp_testa_tags)\n",
    "results4 = list_comparation(ned_train, ned_testa_tokens, ned_testa_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lists</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No lists</td>\n",
       "      <td>0.967353</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.704960</td>\n",
       "      <td>0.777661</td>\n",
       "      <td>0.478458</td>\n",
       "      <td>0.690575</td>\n",
       "      <td>0.751044</td>\n",
       "      <td>1125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lists</td>\n",
       "      <td>0.966913</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.711511</td>\n",
       "      <td>0.793467</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.688204</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lists  Balanced accuracy Total entities  Entities correct  LOC correct  \\\n",
       "0  No lists           0.967353           4274          0.704960     0.777661   \n",
       "1     Lists           0.966913           4274          0.711511     0.793467   \n",
       "\n",
       "   MISC correct  ORG correct  PER correct Entities invented  \n",
       "0      0.478458     0.690575     0.751044              1125  \n",
       "1      0.476190     0.688204     0.766082              1082  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lists</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No lists</td>\n",
       "      <td>0.963677</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.653339</td>\n",
       "      <td>0.624719</td>\n",
       "      <td>0.663158</td>\n",
       "      <td>0.530225</td>\n",
       "      <td>0.785349</td>\n",
       "      <td>680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lists</td>\n",
       "      <td>0.960402</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.661248</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.775128</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Lists  Balanced accuracy Total entities  Entities correct  LOC correct  \\\n",
       "0  No lists           0.963677           2276          0.653339     0.624719   \n",
       "1     Lists           0.960402           2276          0.661248     0.696629   \n",
       "\n",
       "   MISC correct  ORG correct  PER correct Entities invented  \n",
       "0      0.663158     0.530225     0.785349               680  \n",
       "1      0.652632     0.528497     0.775128               641  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En veure els resultats vam comprovar que en els dos casos disminueix lleugerament la \"balanced accuracy\", però hi ha una important millora en les entitats predites correctament.\n",
    "\n",
    "En l'espanyol, els resultats dels tipus tenen molts a veure amb les funcions de les llistes que s'han incorporat. Hi ha una millora al trobar localitzacions i persones, i una petita pèrdua de rendiment en els tipus ORG i MISC. A l'haver incorporat llistes justament de persones i llocs, té sentit que hi hagi una millora. I també té sentit que hi hagi un empitjorament en els altres tipus, perquè segurament les llistes han provocat que organitzacions i altres esdeveniments que abans es predeien bé ara es considerin persones o indrets, perquè alguna de les seves parts activen la funció de nom o localització.\n",
    "\n",
    "En l'holandès passa una cosa una mica més curiosa. Tota la millora es troba en les localitzacions, amb un augment de més 0.07. En canvi, tots els altres tipus empitjoren. Per veure si es devia a algun tipus de desbalanceig vam contar el nombre d'entitats de cada tipus en la partició de validació holandesa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOC:  445\n",
      "MISC:  665\n",
      "ORG:  579\n",
      "PER:  587\n"
     ]
    }
   ],
   "source": [
    "def entity_type_counter(sent_tags):\n",
    "    '''\n",
    "    Count the number of entities of each type\n",
    "    '''\n",
    "    entities = entity_finder(sent_tags)\n",
    "\n",
    "    loc_counter = 0\n",
    "    misc_counter = 0\n",
    "    org_counter = 0\n",
    "    per_counter = 0\n",
    "    \n",
    "    for sent in entities:\n",
    "        for entity in sent:\n",
    "            if entity[0] == 'LOC':\n",
    "                loc_counter += 1\n",
    "            if entity[0] == 'MISC':\n",
    "                misc_counter += 1\n",
    "            if entity[0] == 'ORG':\n",
    "                org_counter += 1\n",
    "            if entity[0] == 'PER':\n",
    "                per_counter += 1\n",
    "\n",
    "    print(\"LOC: \", loc_counter)\n",
    "    print(\"MISC: \", misc_counter)\n",
    "    print(\"ORG: \", org_counter)\n",
    "    print(\"PER: \", per_counter) \n",
    "\n",
    "entity_type_counter(ned_testa_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vam observar que localització era el tipus amb menys presència, així que igual aquest fet tenia alguna cosa a veure. A l'haver-hi menys casos, igual en prediu més i se centra més en aquest tipus empitjorant els altres tres.\n",
    "\n",
    "En tot cas, vam considerar que els models amb les llistes eren millors que sense elles. A part que la capacitat de trobar les entitats correctament era major, també reduïa significativament el nombre d'entitats inventades.\n",
    "\n",
    "Així que, finalment, de les cinc noves \"feature functions\" proposades ens vam quedar amb quatre:\n",
    "\n",
    "- Prefixos\n",
    "\n",
    "- Pos-Tag\n",
    "\n",
    "- Longitud\n",
    "\n",
    "- Llistes de noms i localitzacions\n",
    "\n",
    "Aquestes funcions més les bàsiques serien les usades en l'experimentació del context del següent bloc, i en els models finals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Experimentació de context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop decidides les \"feature functions\" per cada idioma, vam passar al bloc 2, l'experimentació de context. Fins ara només se li donava al model informació del token a predir. Ara, ajustant el \"word_vector\" de GetFeatures podem donar-li al model context de fins a dues paraules abans i després de l'actual.\n",
    "\n",
    "Vam decidir provar totes les combinacions lògiques del vector. Això vol dir que sempre es dona informació de la paraula actual i que no es dona informació de dues paraules més enllà si no es dona informació de la paraula entremig. Al final les combinacions són les següents:\n",
    "\n",
    "- Paraula actual\n",
    "\n",
    "- Paraula anterior, paraula actual\n",
    "\n",
    "- Paraula dos cops anterior, paraula anterior, paraula actual\n",
    "\n",
    "- Paraula actual, paraula següent\n",
    "\n",
    "- Paraula actual, paraula següent, paraula dos cops següent\n",
    "\n",
    "- Paraula anterior, paraula actual, paraula següent\n",
    "\n",
    "- Paraula anterior, paraula actual, paraula següent, paraula dos cops següent\n",
    "\n",
    "- Paraula dos cops anterior, paraula anterior, paraula actual, paraula següent\n",
    "\n",
    "- Paraula dos cops anterior, paraula anterior, paraula actual, paraula següent, paraula dos cops següent\n",
    "\n",
    "Vam crear una funció de \"grid search\" per provar totes les combinacions i vam aplicar-la als dos idiomes. Després vam analitzar els resultats per decidir quin context prendre en cada cas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_vector_search(train, val_tokens, val_tags):\n",
    "    '''\n",
    "    Perform a grid search over the word vector\n",
    "    '''\n",
    "    word_combinations = [[0, 0, 1, 0, 0], [0, 1, 1, 0, 0], [1, 1, 1, 0, 0], [0, 0, 1, 1, 0], [0, 0, 1, 1, 1], [0, 1, 1, 1, 0], [1, 1, 1, 1, 0], [0, 1, 1, 1, 1], [1, 1, 1, 1, 1]]\n",
    "\n",
    "    results = pd.DataFrame(columns=['Word vector', 'Balanced accuracy', 'Total entities', 'Entities correct', 'LOC correct', 'MISC correct', 'ORG correct', 'PER correct', 'Entities invented'])\n",
    "\n",
    "    # Para cada combinación de características\n",
    "    for word_vector in word_combinations:\n",
    "        model = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=True, word_vector=word_vector))\n",
    "        model.train(train, 'crfTagger.mdl')\n",
    "        prediction = model.tag_sents(val_tokens)\n",
    "\n",
    "        _, prediction_tags = sep_token_tag(prediction)\n",
    "\n",
    "        feat_results = evaluate_tagger_performance(val_tags, prediction_tags, word_vector)\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame([feat_results])], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de context en el model de l'idioma espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "results5 = word_vector_search(esp_train, esp_testa_tokens, esp_testa_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word vector</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>0.966913</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.711511</td>\n",
       "      <td>0.793467</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.688204</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 1, 0, 0]</td>\n",
       "      <td>0.968886</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.747075</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.730883</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 0, 0]</td>\n",
       "      <td>0.968291</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.743332</td>\n",
       "      <td>0.805058</td>\n",
       "      <td>0.478458</td>\n",
       "      <td>0.736811</td>\n",
       "      <td>0.801170</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>0.969634</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.716893</td>\n",
       "      <td>0.793467</td>\n",
       "      <td>0.487528</td>\n",
       "      <td>0.700652</td>\n",
       "      <td>0.763576</td>\n",
       "      <td>1102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "      <td>0.967939</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.713383</td>\n",
       "      <td>0.789252</td>\n",
       "      <td>0.430839</td>\n",
       "      <td>0.724956</td>\n",
       "      <td>0.741019</td>\n",
       "      <td>1147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "      <td>0.969691</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.748947</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>0.749259</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1, 1, 1, 0]</td>\n",
       "      <td>0.969250</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.746373</td>\n",
       "      <td>0.804004</td>\n",
       "      <td>0.487528</td>\n",
       "      <td>0.748074</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 1, 1, 1, 1]</td>\n",
       "      <td>0.967246</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.743566</td>\n",
       "      <td>0.812434</td>\n",
       "      <td>0.464853</td>\n",
       "      <td>0.751037</td>\n",
       "      <td>0.781119</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.966442</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.738886</td>\n",
       "      <td>0.801897</td>\n",
       "      <td>0.455782</td>\n",
       "      <td>0.748666</td>\n",
       "      <td>0.779449</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word vector  Balanced accuracy Total entities  Entities correct  \\\n",
       "0  [0, 0, 1, 0, 0]           0.966913           4274          0.711511   \n",
       "1  [0, 1, 1, 0, 0]           0.968886           4274          0.747075   \n",
       "2  [1, 1, 1, 0, 0]           0.968291           4274          0.743332   \n",
       "3  [0, 0, 1, 1, 0]           0.969634           4274          0.716893   \n",
       "4  [0, 0, 1, 1, 1]           0.967939           4274          0.713383   \n",
       "5  [0, 1, 1, 1, 0]           0.969691           4274          0.748947   \n",
       "6  [1, 1, 1, 1, 0]           0.969250           4274          0.746373   \n",
       "7  [0, 1, 1, 1, 1]           0.967246           4274          0.743566   \n",
       "8  [1, 1, 1, 1, 1]           0.966442           4274          0.738886   \n",
       "\n",
       "   LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0     0.793467      0.476190     0.688204     0.766082              1082  \n",
       "1     0.808219      0.507937     0.730883     0.809524               995  \n",
       "2     0.805058      0.478458     0.736811     0.801170               973  \n",
       "3     0.793467      0.487528     0.700652     0.763576              1102  \n",
       "4     0.789252      0.430839     0.724956     0.741019              1147  \n",
       "5     0.802950      0.503401     0.749259     0.796157               980  \n",
       "6     0.804004      0.487528     0.748074     0.793651               986  \n",
       "7     0.812434      0.464853     0.751037     0.781119              1000  \n",
       "8     0.801897      0.455782     0.748666     0.779449               988  "
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Els resultats van ser semblants als esperats. Afegir funcions del context millora el rendiment del model. Però vam observar que donar massa context empitjorava una mica els resultats comparats amb quant es donava menys context.\n",
    "\n",
    "Així doncs, el millor resultat el vam trobar en la següent combinació:\n",
    "\n",
    "- Paraula anterior, paraula actual, paraula següent\n",
    "\n",
    "Millorava tots els tipus d'entitats i també disminuïa bastant el nombre d'entitats inventades. Així que el nostre model final de la llengua espanyola tenia els següents paràmetres:\n",
    "\n",
    "- Features_vector = [1, 1, 1, 0]\n",
    "\n",
    "- Lists = True\n",
    "\n",
    "- Word_vector = [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de context en el model de l'idioma holandès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "results6 = word_vector_search(ned_train, ned_testa_tokens, ned_testa_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word vector</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 0, 1, 0, 0]</td>\n",
       "      <td>0.960402</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.661248</td>\n",
       "      <td>0.696629</td>\n",
       "      <td>0.652632</td>\n",
       "      <td>0.528497</td>\n",
       "      <td>0.775128</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[0, 1, 1, 0, 0]</td>\n",
       "      <td>0.966752</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.708260</td>\n",
       "      <td>0.752809</td>\n",
       "      <td>0.711278</td>\n",
       "      <td>0.538860</td>\n",
       "      <td>0.838160</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1, 1, 1, 0, 0]</td>\n",
       "      <td>0.966723</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.699912</td>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.533679</td>\n",
       "      <td>0.812606</td>\n",
       "      <td>592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[0, 0, 1, 1, 0]</td>\n",
       "      <td>0.960341</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.659490</td>\n",
       "      <td>0.687640</td>\n",
       "      <td>0.678195</td>\n",
       "      <td>0.525043</td>\n",
       "      <td>0.749574</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[0, 0, 1, 1, 1]</td>\n",
       "      <td>0.960488</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.656854</td>\n",
       "      <td>0.689888</td>\n",
       "      <td>0.688722</td>\n",
       "      <td>0.511226</td>\n",
       "      <td>0.739353</td>\n",
       "      <td>675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[0, 1, 1, 1, 0]</td>\n",
       "      <td>0.967169</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.540587</td>\n",
       "      <td>0.819421</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[1, 1, 1, 1, 0]</td>\n",
       "      <td>0.965881</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.705185</td>\n",
       "      <td>0.761798</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.547496</td>\n",
       "      <td>0.807496</td>\n",
       "      <td>585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[0, 1, 1, 1, 1]</td>\n",
       "      <td>0.968334</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.721805</td>\n",
       "      <td>0.547496</td>\n",
       "      <td>0.816014</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "      <td>0.966226</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.706503</td>\n",
       "      <td>0.743820</td>\n",
       "      <td>0.726316</td>\n",
       "      <td>0.552677</td>\n",
       "      <td>0.807496</td>\n",
       "      <td>589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word vector  Balanced accuracy Total entities  Entities correct  \\\n",
       "0  [0, 0, 1, 0, 0]           0.960402           2276          0.661248   \n",
       "1  [0, 1, 1, 0, 0]           0.966752           2276          0.708260   \n",
       "2  [1, 1, 1, 0, 0]           0.966723           2276          0.699912   \n",
       "3  [0, 0, 1, 1, 0]           0.960341           2276          0.659490   \n",
       "4  [0, 0, 1, 1, 1]           0.960488           2276          0.656854   \n",
       "5  [0, 1, 1, 1, 0]           0.967169           2276          0.709578   \n",
       "6  [1, 1, 1, 1, 0]           0.965881           2276          0.705185   \n",
       "7  [0, 1, 1, 1, 1]           0.968334           2276          0.706503   \n",
       "8  [1, 1, 1, 1, 1]           0.966226           2276          0.706503   \n",
       "\n",
       "   LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0     0.696629      0.652632     0.528497     0.775128               641  \n",
       "1     0.752809      0.711278     0.538860     0.838160               573  \n",
       "2     0.746067      0.714286     0.533679     0.812606               592  \n",
       "3     0.687640      0.678195     0.525043     0.749574               662  \n",
       "4     0.689888      0.688722     0.511226     0.739353               675  \n",
       "5     0.775281      0.715789     0.540587     0.819421               574  \n",
       "6     0.761798      0.714286     0.547496     0.807496               585  \n",
       "7     0.746067      0.721805     0.547496     0.816014               591  \n",
       "8     0.743820      0.726316     0.552677     0.807496               589  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el cas del holandès vam veure un resultat molt semblant. El context millora el rendiment del model, però si es dona massa context comença a anar pitjor. \n",
    "\n",
    "Així que el resultat del context va tornar a ser el mateix:\n",
    "\n",
    "- Paraula anterior, paraula actual, paraula següent\n",
    "\n",
    "També millora totes els tipus de entitats i torna a disminuir el nombre d'entitats inventades. Així que el nostre model final de la llengua holandesa va tenir els següents paràmetres:\n",
    "\n",
    "- Features_vector = [1, 1, 1, 0]\n",
    "\n",
    "- Lists = True\n",
    "\n",
    "- Word_vector = [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Experimentació de les codificacions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop vam tenir els dos models finals creats, vam provar-los en diferents codificacions per escollir-ne una. Vam decidir provar sobre les següents codificacions:\n",
    "\n",
    "- IO\n",
    "\n",
    "- BIO\n",
    "\n",
    "- BIOE\n",
    "\n",
    "- BIOS\n",
    "\n",
    "- BIOES\n",
    "\n",
    "El primer que vam fer és crear diferents funcions que generessin les noves codificacions. Es troben a continuació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_to_IO(train):\n",
    "    '''\n",
    "    Convert the train to IO format\n",
    "    '''\n",
    "    train_io = []\n",
    "    for sent in train:\n",
    "        sent_io = []\n",
    "        for word in sent:\n",
    "            new_tag = re.sub(r'\\bB-', 'I-', word[1])\n",
    "            sent_io.append((word[0], new_tag))\n",
    "        train_io.append(sent_io)\n",
    "    return train_io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train_IO = train_to_IO(esp_train)\n",
    "ned_train_IO = train_to_IO(ned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_to_BIOE(train):\n",
    "    '''\n",
    "    Convert the train to BIOE format\n",
    "    '''\n",
    "    train_bioe = []\n",
    "    for sent in train:\n",
    "        sent_bioe = []\n",
    "        for i in range(len(sent)):\n",
    "            tag = sent[i][1]\n",
    "            if tag[0] == 'I' and (i == len(sent) - 1 or sent[i + 1][1][0] != 'I'):\n",
    "                tag = re.sub(r'\\bI-', 'E-', tag)\n",
    "            sent_bioe.append((sent[i][0], tag))\n",
    "        train_bioe.append(sent_bioe)\n",
    "    return train_bioe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train_BIOE = train_to_BIOE(esp_train)\n",
    "ned_train_BIOE = train_to_BIOE(ned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_to_BIOS(train):\n",
    "    '''\n",
    "    Convert the train to BIOS format\n",
    "    '''\n",
    "    train_bios = []\n",
    "    for sent in train:\n",
    "        sent_bios = []\n",
    "        for i in range(len(sent)):\n",
    "            tag = sent[i][1]\n",
    "            if tag[0] == 'B' and (i == len(sent) - 1 or sent[i + 1][1][0] == 'O'):\n",
    "                tag = re.sub(r'\\bB-', 'S-', tag)\n",
    "            sent_bios.append((sent[i][0], tag))\n",
    "        train_bios.append(sent_bios)\n",
    "    return train_bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train_BIOS = train_to_BIOS(esp_train)\n",
    "ned_train_BIOS = train_to_BIOS(ned_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_to_BIOES(train):\n",
    "    '''\n",
    "    Convert the train to BIOES format\n",
    "    '''\n",
    "    train_bios = train_to_BIOS(train)\n",
    "    train_bioes = train_to_BIOE(train_bios)\n",
    "    return train_bioes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "esp_train_BIOES = train_to_BIOES(esp_train)\n",
    "ned_train_BIOES = train_to_BIOES(ned_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop creades totes les noves particions de train amb les 5 codificacions, vam crear una funció de \"grid search\" per provar les diferents codificacions en cada idioma, i veure els resultats en una taula.\n",
    "\n",
    "La funció es troba a continuació."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "cod_train_esp = [esp_train, esp_train_IO, esp_train_BIOE, esp_train_BIOS, esp_train_BIOES]\n",
    "cod_train_ned = [ned_train, ned_train_IO, ned_train_BIOE, ned_train_BIOS, ned_train_BIOES]\n",
    "cod = ['BIO','IO', 'BIOE', 'BIOS', 'BIOES']\n",
    "\n",
    "def cod_grid_search(trains, val_tokens, val_tags, cod):\n",
    "    '''\n",
    "    Perform a grid search over the codification\n",
    "    '''\n",
    "    results = pd.DataFrame(columns=['Codification', 'Balanced accuracy', 'Total entities', 'Entities correct', 'LOC correct', 'MISC correct', 'ORG correct', 'PER correct', 'Entities invented'])\n",
    "\n",
    "    # Para cada combinación de características\n",
    "    for i in range(len(trains)):\n",
    "        model = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=True, word_vector=[0, 1, 1, 1, 0]))\n",
    "        model.train(trains[i], 'crfTagger.mdl')\n",
    "        prediction = model.tag_sents(val_tokens)\n",
    "\n",
    "        _, prediction_tags = sep_token_tag(prediction)\n",
    "\n",
    "        feat_results = evaluate_tagger_performance(val_tags, prediction_tags, cod[i])\n",
    "\n",
    "        results = pd.concat([results, pd.DataFrame([feat_results])], ignore_index=True)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de codificacions en el model espanyol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "results7 = cod_grid_search(cod_train_esp, esp_testa_tokens, esp_testa_tags, cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codification</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIO</td>\n",
       "      <td>0.969691</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.748947</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>0.503401</td>\n",
       "      <td>0.749259</td>\n",
       "      <td>0.796157</td>\n",
       "      <td>980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IO</td>\n",
       "      <td>0.969260</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.742630</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.485261</td>\n",
       "      <td>0.730883</td>\n",
       "      <td>0.802005</td>\n",
       "      <td>973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIOE</td>\n",
       "      <td>0.969614</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.747777</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>0.501134</td>\n",
       "      <td>0.747481</td>\n",
       "      <td>0.795322</td>\n",
       "      <td>988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIOS</td>\n",
       "      <td>0.971475</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.745905</td>\n",
       "      <td>0.812434</td>\n",
       "      <td>0.510204</td>\n",
       "      <td>0.738589</td>\n",
       "      <td>0.790309</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIOES</td>\n",
       "      <td>0.971310</td>\n",
       "      <td>4274</td>\n",
       "      <td>0.749181</td>\n",
       "      <td>0.813488</td>\n",
       "      <td>0.507937</td>\n",
       "      <td>0.750445</td>\n",
       "      <td>0.785297</td>\n",
       "      <td>1007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Codification  Balanced accuracy Total entities  Entities correct  \\\n",
       "0          BIO           0.969691           4274          0.748947   \n",
       "1           IO           0.969260           4274          0.742630   \n",
       "2         BIOE           0.969614           4274          0.747777   \n",
       "3         BIOS           0.971475           4274          0.745905   \n",
       "4        BIOES           0.971310           4274          0.749181   \n",
       "\n",
       "   LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0     0.802950      0.503401     0.749259     0.796157               980  \n",
       "1     0.808219      0.485261     0.730883     0.802005               973  \n",
       "2     0.802950      0.501134     0.747481     0.795322               988  \n",
       "3     0.812434      0.510204     0.738589     0.790309              1002  \n",
       "4     0.813488      0.507937     0.750445     0.785297              1007  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després de provar les diferents codificacions en el model espanyol, vam observar que no hi havia pràcticament diferència entres elles.\n",
    "\n",
    "La codificació que millor \"balanced accuracy\" i precisió en detectar entitats donava era la codificació BIOES, però amb una diferència mínima respecte a la codificació original. A part, la codificació BIOES augmentava una mica el nombre d'entitats inventades, així que vam decidir mantenir la codificació original, la BIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi de codificacions en el model holandès"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "results8 = cod_grid_search(cod_train_ned, ned_testa_tokens, ned_testa_tags, cod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Codification</th>\n",
       "      <th>Balanced accuracy</th>\n",
       "      <th>Total entities</th>\n",
       "      <th>Entities correct</th>\n",
       "      <th>LOC correct</th>\n",
       "      <th>MISC correct</th>\n",
       "      <th>ORG correct</th>\n",
       "      <th>PER correct</th>\n",
       "      <th>Entities invented</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIO</td>\n",
       "      <td>0.967169</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.709578</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.715789</td>\n",
       "      <td>0.540587</td>\n",
       "      <td>0.819421</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IO</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.703866</td>\n",
       "      <td>0.766292</td>\n",
       "      <td>0.693233</td>\n",
       "      <td>0.561313</td>\n",
       "      <td>0.809199</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIOE</td>\n",
       "      <td>0.964893</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.706942</td>\n",
       "      <td>0.759551</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.535406</td>\n",
       "      <td>0.827939</td>\n",
       "      <td>573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BIOS</td>\n",
       "      <td>0.964026</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.694640</td>\n",
       "      <td>0.746067</td>\n",
       "      <td>0.703759</td>\n",
       "      <td>0.518135</td>\n",
       "      <td>0.819421</td>\n",
       "      <td>602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BIOES</td>\n",
       "      <td>0.963874</td>\n",
       "      <td>2276</td>\n",
       "      <td>0.700351</td>\n",
       "      <td>0.748315</td>\n",
       "      <td>0.709774</td>\n",
       "      <td>0.526770</td>\n",
       "      <td>0.824532</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Codification  Balanced accuracy Total entities  Entities correct  \\\n",
       "0          BIO           0.967169           2276          0.709578   \n",
       "1           IO           0.966092           2276          0.703866   \n",
       "2         BIOE           0.964893           2276          0.706942   \n",
       "3         BIOS           0.964026           2276          0.694640   \n",
       "4        BIOES           0.963874           2276          0.700351   \n",
       "\n",
       "   LOC correct  MISC correct  ORG correct  PER correct Entities invented  \n",
       "0     0.775281      0.715789     0.540587     0.819421               574  \n",
       "1     0.766292      0.693233     0.561313     0.809199               597  \n",
       "2     0.759551      0.714286     0.535406     0.827939               573  \n",
       "3     0.746067      0.703759     0.518135     0.819421               602  \n",
       "4     0.748315      0.709774     0.526770     0.824532               595  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el cas de l'holandès el resultat no va ser gaire diferent. El fet de canviar la codificació no canviava gaire el resultat. De fet, en aquest cas, totes les codificacions empitjoraven respecte de l'original.\n",
    "\n",
    "Així que no va haver-hi gaire dubte en aquest cas. Igual que en l'idioma espanyol, vam seleccionar com a definitiva la codificació BIO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Anàlisi dels models definitius"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un cop ja vam passar els primers tres blocs, vam trobar dos models definitius.\n",
    "\n",
    "En el primer bloc vam seleccionar quines \"feature functions\" utilitzaríem. Al final van resultar ser en els dos casos les 5 funcions bàsiques, els prefixos, el Pos-Tag i la longitud.\n",
    "\n",
    "En el segon bloc vam determinar quin context usar. Vam considerar en els dos idiomes el mateix context, la paraula anterior, actual i següent.\n",
    "\n",
    "En el tercer i últim bloc d'experimentació vam experimentar amb diferents codificacions per escollir-ne una, i finalment vam comprovar que l'original era la millor en ambdós casos.\n",
    "\n",
    "Un cop vam tenir els dos models definits els vam aplicar al test per veure els resultats, i també vam analitzar els errors per veure en quins casos no detectava entitats i en quins casos se les inventava."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi dels resultats i errors del model espanyol sobre el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_esp = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=True, word_vector=[0, 1, 1, 1, 0]))\n",
    "model_esp.train(esp_train, 'crfTagger.mdl')\n",
    "prediction_esp = model_esp.tag_sents(esp_testb_tokens)\n",
    "\n",
    "_, prediction_esp_tags = sep_token_tag(prediction_esp)\n",
    "\n",
    "results, errors = evaluate_tagger_performance(esp_testb_tags, prediction_esp_tags, features=[1,1,1,0], errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Codification': [1, 1, 1, 0],\n",
       " 'Balanced accuracy': 0.9705465184033057,\n",
       " 'Total entities': 3536,\n",
       " 'Entities correct': 0.7864819004524887,\n",
       " 'LOC correct': 0.7684407096171803,\n",
       " 'MISC correct': 0.45722713864306785,\n",
       " 'ORG correct': 0.8254649499284692,\n",
       " 'PER correct': 0.8914835164835165,\n",
       " 'Entities invented': 720}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vam entrenar el model definitiu de l'espanyol amb tots els paràmetres seleccionats al llarg de la pràctica. I el vam aplicar a la partició de test.\n",
    "\n",
    "Els resultats són molt bons. La \"accuracy\" balancejada és molt alta, el que significa que localitza molt bé les entitats. Quant a predir perfectament la posició i tipus de les entitats, prediu correctament quasi el 80% de les entitats. I prediu molt bé les persones, amb una precisió de quasi el 90%. El tipus pitjor predit és el de MISC, com ja passava a la validació.\n",
    "\n",
    "Vam voler analitzar alguns casos en els quals el model fallava per poder fer una millor anàlisi d'aquest. Per fer-ho vam utilitzar el paràmetre errors de la funció evaluate_tagger_performance. A continuació vam analitzar alguns casos aleatoris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['Vallehermoso', ',', 'la', 'única', 'inmobiliaria', 'española', 'que', 'forma', 'parte', 'del', 'índice', 'Ibex-35', ',', 'obtuvo', 'en', 'el', 'primer', 'trimestre', 'de', 'este', 'año', 'unos', 'beneficios', 'antes', 'de', 'impuestos', 'de', '4.711', 'millones', 'de', 'pesetas', ',', 'un', '32,5', 'por', 'ciento', 'más', 'que', 'en', 'el', 'ejercicio', 'precedente', '.']\n",
      "Real tags: ['B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted tags: ['B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(21)\n",
    "# Escoge un error aleatorio\n",
    "error = random.choice(errors)\n",
    "\n",
    "idx = error[0]\n",
    "entity = error[1]\n",
    "\n",
    "sentence_bad = esp_testb[idx]\n",
    "\n",
    "sentence = [token[0] for token in sentence_bad]\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "\n",
    "print(\"Real tags:\", [tag for tag in esp_testb_tags[idx]])\n",
    "\n",
    "print(\"Predicted tags:\", [tag[1] for tag in prediction_esp[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest primer exemple es pot veure que l'errada està en la primera paraula. Realment és una organització, però es prediu com a localització. És un error que es pot entendre, ja que realment sembla el nom d'un lloc, i per tant no és una gran errada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['La', 'Asociación', '\"', 'Sancho', 'Ramírez', '\"', 'de', 'Jaca', '(', 'Huesca', ')', 'ha', 'puesto', 'en', 'marcha', 'un', 'concurso', 'de', 'fotografía', 'y', 'dibujo', 'sobre', 'la', '\"', 'Arquitectura', 'popular', 'en', 'el', 'Pirineo', 'Aragonés', '\"', ',', 'con', 'el', 'objetivo', 'de', 'llamar', 'la', 'atención', 'sobre', 'el', 'patrimonio', 'para', 'que', 'sea', 'protegido', ',', 'conservado', 'y', 'difundido', '.']\n",
      "Real tags: ['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted tags: ['O', 'B-ORG', 'I-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'B-LOC', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(23)\n",
    "# Escoge un error aleatorio\n",
    "error = random.choice(errors)\n",
    "\n",
    "idx = error[0]\n",
    "entity = error[1]\n",
    "\n",
    "sentence_bad = esp_testb[idx]\n",
    "\n",
    "sentence = [token[0] for token in sentence_bad]\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "\n",
    "print(\"Real tags:\", [tag for tag in esp_testb_tags[idx]])\n",
    "\n",
    "print(\"Predicted tags:\", [tag[1] for tag in prediction_esp[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquest segon cas és molt més complex. Les entitats són molt més llargues i això provoca que el model no les acabi de detectar totes correctament. Així que el model pot fallar en casos on hi ha entitats extenses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions del model espanyol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Després d'aplicar el model al test vam obtenir uns bons resultats. 4 de cada 5 entitats són detectades perfectament, i pràcticament totes les entitats són ubicades, encara que no amb el tipus correcte.\n",
    "\n",
    "Pel vist al test, el model és especialment bo per predir persones, i també dona un molt bon resultat en localitzacions i organitzacions. El tipus MISC és el que més costa de detectar correctament, i la precisió és del 50%.\n",
    "\n",
    "Amb l'anàlisi d'errors vam poder veure que el model fallava en casos realment complicats, amb dues dinàmiques principals:\n",
    "\n",
    "-Paraules estranyes que es prediuen com un tipus que no són, com per exemple l'error 1\n",
    "\n",
    "-Entitats extenses que no s'acaben de predir correctament, com per exemple l'error 2\n",
    "\n",
    "Al llarg de la pràctica hem anat definint les millors opcions a través de la validació, i creiem després dels tres blocs ha quedat un molt bon model final, que ubica pràcticament totes les entitats, i que a vegades falla a l'hora de precisar el tipus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anàlisi dels resultats i errors del model holandès sobre el test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ned = nltk.tag.CRFTagger(feature_func=GetFeatures(features_vector=[1, 1, 1, 0], lists=True, word_vector=[0, 1, 1, 1, 0]))\n",
    "model_ned.train(ned_train, 'crfTagger.mdl')\n",
    "prediction_ned = model_ned.tag_sents(ned_testb_tokens)\n",
    "\n",
    "_, prediction_ned_tags = sep_token_tag(prediction_ned)\n",
    "\n",
    "results2, errors2 = evaluate_tagger_performance(ned_testb_tags, prediction_ned_tags, features=[1,1,1,0], errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Codification': [1, 1, 1, 0],\n",
       " 'Balanced accuracy': 0.9652629808175924,\n",
       " 'Total entities': 3409,\n",
       " 'Entities correct': 0.7450865356409504,\n",
       " 'LOC correct': 0.8066298342541437,\n",
       " 'MISC correct': 0.6887417218543046,\n",
       " 'ORG correct': 0.5904109589041096,\n",
       " 'PER correct': 0.8875278396436526,\n",
       " 'Entities invented': 746}"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vam entrenar el model definitiu holandès amb tots els paràmetres definits durant l'experimentació, i el vam aplicar al test.\n",
    "\n",
    "Els resultats ens van sorprendre bastant, ja que eren superiors al vist en la validació. La \"accuracy\" balancejada és molt alta, el que significa que s'ubiquen molt bé les entitats. El percentatge d'entitats predites perfectament és del 75%, una mica inferior que en el model espanyol. Un altre cop el test ens diu que és un bon model per predir persones. Igual que l'espanyol també té una alta precisió en les localitzacions, de fet més. Però on hi ha molta diferència és a ORG i MISC. En aquest idioma MISC es prediu molt millor que a l'espanyol, i amb les organitzacions passa el contrari, es prediuen molt pitjor que en l'espanyol.\n",
    "\n",
    "També vam fer una anàlisi d'errors aleatoris en aquest idioma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['Transparency', 'International', '(', 'TI', ')', ',', 'de', 'onderhand', 'in', '75', 'naties', 'vertegenwoordigde', 'Berlijnse', 'ngo', 'die', 'strijd', 'voert', 'tegen', 'corruptie', 'en', 'jaarlijks', 'een', 'Index', 'van', 'Corruptie', 'Perceptie', 'opstelt', ',', 'wil', 'dat', 'de', 'Wereldbank', 'een', 'tienpuntenplan', 'uitvoert', 'om', 'ontwikkelingslanden', 'die', 'geld', 'bij', 'haar', 'lenen', 'op', 'het', 'rechte', 'pad', 'te', 'houden', '.']\n",
      "Real tags: ['B-ORG', 'I-ORG', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'I-MISC', 'I-MISC', 'I-MISC', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted tags: ['B-MISC', 'I-MISC', 'O', 'B-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-MISC', 'O', 'B-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(23)\n",
    "# Escoge un error aleatorio\n",
    "error = random.choice(errors2)\n",
    "\n",
    "idx = error[0]\n",
    "entity = error[1]\n",
    "\n",
    "sentence_bad = ned_testb[idx]\n",
    "\n",
    "sentence = [token[0] for token in sentence_bad]\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "\n",
    "print(\"Real tags:\", [tag for tag in ned_testb_tags[idx]])\n",
    "\n",
    "print(\"Predicted tags:\", [tag[1] for tag in prediction_ned[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En aquest primer exemple hi ha molts errors a l'hora de detectar el tipus d'entitat. També trobem un patró identificat en l'espanyol, entitats molt llargues que no s'acaben de detectar bé perquè se separen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence:  ['Scholen', 'die', 'Test-Aankoop', 'in', 'het', 'voorjaar', 'enquêteformulieren', 'toestuurde', ',', 'kregen', 'van', 'hogerhand', 'de', 'raad', 'niet', 'mee', 'te', 'werken', '.']\n",
      "Real tags: ['O', 'O', 'B-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Predicted tags: ['O', 'O', 'B-MISC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(11)\n",
    "# Escoge un error aleatorio\n",
    "error = random.choice(errors2)\n",
    "\n",
    "idx = error[0]\n",
    "entity = error[1]\n",
    "\n",
    "sentence_bad = ned_testb[idx]\n",
    "\n",
    "sentence = [token[0] for token in sentence_bad]\n",
    "\n",
    "print(\"Sentence: \", sentence)\n",
    "\n",
    "print(\"Real tags:\", [tag for tag in ned_testb_tags[idx]])\n",
    "\n",
    "print(\"Predicted tags:\", [tag[1] for tag in prediction_ned[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I en aquest segon exemple veiem un altre cop un cas en el qual només es falla el tipus, però la ubicació de l'entitat és perfecte. És l'error general, errada a l'hora d'identificar el tipus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions del model holandès"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El model holandès va obtenir resultats pitjors que el model espanyol, però gens dolents. En aquest cas 3 de cada 4 entitats són identificades a la perfecció, i un molt alt percentatge de les entitats s'ubiquen encara que no es trobi el tipus exacte.\n",
    "\n",
    "Torna a ser especialment bo en detectar persones, i molt bo també en les localitzacions. Però en aquest cas el model si té més problemes per identificar les organitzacions. El tipus MISC s'identifica bastant millor que en l'espanyol, sent l'aspecte en el qual més destaca davant l'altre model.\n",
    "\n",
    "Els errors segueixen sent quasi sempre per no identificar correctament el tipus de l'entitat, i igual que a l'espanyol, les entitats llargues són les que més problemes porten.\n",
    "\n",
    "En definitiva, és un bon model, que troba quasi totes les entitats i que en la majoria dels casos identifica correctament el seu tipus."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
